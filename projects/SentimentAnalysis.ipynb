{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Information:\n",
    "    \n",
    "- Tag data item with values for sentiments\n",
    "- One/More categorical data series created\n",
    "- Analysing categorical sentiment data\n",
    "\n",
    "### Act:\n",
    "\n",
    "- Trade financial market\n",
    "- Change or reallocate ad budgets\n",
    "- Tailor electoral strategy\n",
    "- Decide product recall strategies\n",
    "\n",
    "### Applications of sentiment analysis:\n",
    "\n",
    "- Event-driven Trading (Company earnings vs Forecast) Buy the Rumor , Sell the News\n",
    "- \n",
    "\n",
    "Polarity: Positive or negative?\n",
    "Subjectivity: Subjective or objective?\n",
    "Aspects: Part or whole?\n",
    "\n",
    "### Rule-based and ML-based Binary Classifiers:\n",
    "Static vs. Dynamic\n",
    "Experts needed to formulate rules vs. No need expert skill   \n",
    "Corpus of data needed, can not operate on isolated problem instances vs. can operate on isolated problem instances\n",
    "To update classifier, update corpus vs. To update classifier, update rules\n",
    "Require training step vs. No training step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule based approached\n",
    "\n",
    "Building is hard, Using is easy:\n",
    "\n",
    "- Split text into words\n",
    "- Calculate polarity of individual words (requires use of a sentiment lexicon, ignore stop and neutral words)\n",
    "- Aggregate word polarities\n",
    "\n",
    "Limitations of a Simplistic Approach:\n",
    "- Polarity alone loses intensity information\n",
    "\n",
    "VADER (Valence Aware Dictionary for sEntiment Reasoning) \n",
    " \n",
    " - Builtt in nltk\n",
    " - Both algorithm and dataset\n",
    " - Support for Emoticons, Idioms, Punction, Negation, Double Negation, Emphasis, Contrast and Boost word (So, Really)\n",
    " \n",
    "Sentiwordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jli\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': -0.4767, 'neg': 0.608, 'neu': 0.392, 'pos': 0.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia = vader.SentimentIntensityAnalyzer()\n",
    "sia.polarity_scores(\"What a terrible restaurant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Movie Review with VADER \n",
    "\n",
    "downlown data from [here](https://www.cs.cornell.edu/people/pabo/movie-review-data/). This dataset contains two files each has 5331 positive or negative processed sentences/snippets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\jli\\Downloads\\rt-polaritydata\\rt-polaritydata\\rt-polarity.pos') as pf:\n",
    "    posReviews = pf.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5331"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posReviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . \\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posReviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\jli\\Downloads\\rt-polaritydata\\rt-polaritydata\\rt-polarity.neg') as pf:\n",
    "    negReviews = pf.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5331"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negReviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'simplistic , silly and tedious . \\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negReviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import vader\n",
    "sia = vader.SentimentIntensityAnalyzer()\n",
    "def vaderSentiment(review):\n",
    "    return sia.polarity_scores(review)['compound']\n",
    "\n",
    "def getReviewSentiment(sentimentCalculator):\n",
    "    posCompound = [sentimentCalculator(review) for review in posReviews]\n",
    "    negCompound = [sentimentCalculator(review) for review in negReviews]\n",
    "    \n",
    "    return {'Positive_Reviews': posCompound, 'Negative_Reviews': negCompound}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vaderResults = getReviewSentiment(vaderSentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Positive_Reviews', 'Negative_Reviews']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaderResults.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5331"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vaderResults['Positive_Reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3612,\n",
       " 0.8069,\n",
       " 0.2617,\n",
       " 0.8271,\n",
       " 0.6592,\n",
       " 0.5994,\n",
       " 0.4215,\n",
       " -0.5994,\n",
       " 0.0938,\n",
       " 0.4939]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaderResults['Positive_Reviews'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.694428812606\n"
     ]
    }
   ],
   "source": [
    "# calculate the accuracy on positive reviews\n",
    "pos_accuracy = sum(1.0 for x in vaderResults['Positive_Reviews'] if x > 0 ) / len(vaderResults['Positive_Reviews'])\n",
    "print(pos_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.400862877509\n"
     ]
    }
   ],
   "source": [
    "neg_accuracy = sum(1.0 for x in vaderResults['Negative_Reviews'] if x < 0 ) / len(vaderResults['Negative_Reviews'])\n",
    "print(neg_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runDiagnostics(reviewResult):\n",
    "    posReviewResults = reviewResult['Positive_Reviews']\n",
    "    negReviewResults = reviewResult['Negative_Reviews']\n",
    "    \n",
    "    pctTruePos = float(sum(x > 0 for x in posReviewResults)) / len(posReviewResults)\n",
    "    pctTrueNeg = float(sum(x < 0 for x in negReviewResults)) / len(negReviewResults)\n",
    "    overallPct = (pctTruePos + pctTrueNeg) / 2\n",
    "    print \"Accuracy on positive reviews = \" + \"%.2f\" % (pctTruePos*100) + \"%\"\n",
    "    print \"Accuracy on negative reviews = \" + \"%.2f\" % (pctTrueNeg*100) + \"%\"\n",
    "    print \"Overall Accuracy = \" + \"%.2f\" % (overallPct*100) + \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on positive reviews = 69.44%\n",
      "Accuracy on negative reviews = 40.09%\n",
      "Overall Accuracy = 54.76%\n"
     ]
    }
   ],
   "source": [
    "runDiagnostics(getReviewSentiment(vaderSentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Movie Review with Sentiwordnet\n",
    "\n",
    " - Words, Lemmas, Synsets\n",
    " - Sentiwordnet extends wordnet with polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SentiSynset('dog.n.01'),\n",
       " SentiSynset('frump.n.01'),\n",
       " SentiSynset('dog.n.03'),\n",
       " SentiSynset('cad.n.01'),\n",
       " SentiSynset('frank.n.02'),\n",
       " SentiSynset('pawl.n.01'),\n",
       " SentiSynset('andiron.n.01'),\n",
       " SentiSynset('chase.v.01')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swn.senti_synsets('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swn.senti_synsets('dog')[3].neg_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swn.senti_synsets('dog')[3].pos_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "def superNaiveSentiment(review):\n",
    "    reviewPolarity = 0.0\n",
    "    numExceptions = 0\n",
    "    \n",
    "    for word in review.lower().split():\n",
    "        weight = 0.0\n",
    "        try:\n",
    "            common_meaning = swn.senti_synsets(word)[0]  # only relys on the first common meaning\n",
    "            if common_meaning.pos_score() > common_meaning.neg_score():\n",
    "                weight += common_meaning.pos_score()\n",
    "            elif common_meaning.pos_score() < common_meaning.neg_score():\n",
    "                weight -= common_meaning.neg_score()\n",
    "        except:\n",
    "            numExceptions += 1\n",
    "        reviewPolarity += weight\n",
    "    return reviewPolarity        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on positive reviews = 69.44%\n",
      "Accuracy on negative reviews = 40.09%\n",
      "Overall Accuracy = 54.76%\n"
     ]
    }
   ],
   "source": [
    "runDiagnostics(getReviewSentiment(superNaiveSentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "def naiveSentiment(review):\n",
    "    reviewPolarity = 0.0\n",
    "    numExceptions = 0\n",
    "    \n",
    "    for word in review.lower().split():\n",
    "        numMeanings = 0\n",
    "        if word in stopwords:\n",
    "            continue\n",
    "        weight = 0.0\n",
    "        try:\n",
    "            for meaning in swn.senti_synsets(word):\n",
    "                if meaning.pos_score() > meaning.neg_score():\n",
    "                    weight += (meaning.pos_score() - meaning.neg_score())\n",
    "                    numMeanings += 1\n",
    "                elif meaning.pos_score() < meaning.neg_score():\n",
    "                    weight -= (meaning.neg_score() - meaning.pos_score())\n",
    "                    numMeanings += 1\n",
    "        except:\n",
    "            numExceptions += 1\n",
    "        if numMeanings > 0:\n",
    "            reviewPolarity += (weight/numMeanings)\n",
    "    return reviewPolarity    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on positive reviews = 69.44%\n",
      "Accuracy on negative reviews = 40.09%\n",
      "Overall Accuracy = 54.76%\n"
     ]
    }
   ],
   "source": [
    "runDiagnostics(getReviewSentiment(naiveSentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
