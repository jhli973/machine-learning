{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Interval and P-value\n",
    "\n",
    "- P-values are used to determine whether a null hypothesis is to be accepted or rejected. The p-value is a probability reflects the measure of evidence against the null hypothesis. To make a decision between accepted or rejected, significant limits are specified in advance at the level of significance alpha, by default it is 0.05. If p-value is less than this limit, the result is significant and the null hypothesis should be rejected. However, p-value alone does not permit any direct statement about the direction. \n",
    "\n",
    "- Confidence interval is a range of values calculated by statistical methods with a probability defined (usually is 95%). This means that the confidence interval covers the true value in 95 out 100 studies performed. The advantage of confidence limits in comparision with p-value is that they reflect the results at the level of data measurement. Confidence interals indicate the direction of the effect studied.\n",
    "\n",
    "- If a confidence intervals is given, several conclusions can be made. First, values below the lower limit or above the upper limit are not excluded but are unlikely. With the confidence limit of 95%, each of these probabilities is only 2.5%. Velues within the confidence limits but near to the limits are mostly less probabble than values near the point estimate\n",
    "\n",
    "For example, an experiment to test if two drugs have different effects on blood pressure. The null hypothesis might be \"there is no difference between the two drug with respect to their effect on the blood pressure. The alternative hypothesis can either be formulated as a two-tailed hypothesis (any difference) or a one-tailed hypothesis (positive or negative effect). check [here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2689604/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA vs T-Test, One-way and two-way\n",
    "\n",
    "A Student’s t-test will tell you if there is a significant variation between groups. A t-test compares means, while the ANOVA compares variances between populations.\n",
    "\n",
    "You could technically perform a series of t-tests on your data. However, as the groups grow in number, you may end up with a lot of pair comparisons that you need to run. ANOVA will give you a single number (the f-statistic) and one p-value to help you support or reject the null hypothesis.\n",
    "\n",
    "One-way or two-way refers to the number of independent variables (IVs) in your Analysis of Variance test. One-way has one independent variable (with 2 levels) and two-way has two independent variables (can have multiple levels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simpson paradox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data\n",
    "\n",
    "There are generall 3 different scenario [check here](http://stats.stackexchange.com/questions/124409/how-to-handle-missing-data-in-a-small-n-large-k-machine-learning-scenario?rq=1):\n",
    "- Missing completely at random (MCAR) - Ideal situation, nothing can explain that certain values are missing\n",
    "- Missing at Random (MAR) - Data is missing conditionally at random and the data may depend on an observed measurement\n",
    "- Missing not at random (NMAR) - Data is missing conditionally at random and the data may depend on an unobserved measurement. Worest scenario\n",
    "\n",
    "If your data fit either MCAR or MAR you can jump in to the next stage. If NMAR, then you should be very cautious and explore specific methods for this scenario. Next, naturally it depends on your data. There are several simple methods that may work very well if you are missing only a few data points. These include mean, median, and minimum imputation. \n",
    "\n",
    "Unfortunately there is no 'gold standard' and many times researchers simply exclude samples with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Multicollinearity\n",
    "\n",
    "Multicollinearity exists whenever two or more of the predictors in a regression model are moderately or highly correlated. \n",
    "\n",
    "There are two types of multicollinearity:\n",
    "- Structural multicollinearity is a mathematical artifact caused by creating new predictors from other predictors — such as, creating the predictor x2 from the predictor x.\n",
    "- Data-based multicollinearity, on the other hand, is a result of a poorly designed experiment, reliance on purely observational data, or the inability to manipulate the system on which the data are collected. Data-based multicollinearity is the more troublesome of the two types of multicollinearity. Unfortunately it is the type we encounter most often!\n",
    "\n",
    "The major effects that multicollinearity has on our use of a regression model in the presence of multicollinearity:\n",
    "- It is okay to use an estimated regression model to predict y or estimate μY as long as you do so within the scope of the model.\n",
    "- We can no longer make much sense of the usual interpretation of a slope coefficient as the change in the mean response for each additional unit increase in the predictor xk, when all the other predictors are held constant.\n",
    "\n",
    "Variance Inflation Factor (VIF) - This metric is used to check multicollinearity. VIF <=4 implies no multicollinearity but VIF >=10 suggests high multicollinearity. Alternatively, you can also look at the tolerance (1/VIF) value to determine correlation in IVs. In addition, you can also create a correlation matrix to determine collinear variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
